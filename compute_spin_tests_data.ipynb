{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spin tests\n",
    "\n",
    "This notebook contains the code used to perform the spin-tests contained in the study. Note that it **not** necessary to run this notebook to obtain the spin-test data, since it was already precomputed and stored in the folder `spin-test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rot_metrics_on_annot(map_data_lh, map_data_rh,\n",
    "                                 annot_lh, annot_rh,\n",
    "                                 rot_indices_lh, rot_indices_rh,\n",
    "                                 agg_function, annot_parcel_names_dict=None,\n",
    "                                 join_hemi=True):\n",
    "    \"\"\"Computes the metrics provided in the maps aggregated on the parcellations provided in the annotation files for each spin permutation\"\"\"\n",
    "\n",
    "    df_lh = pd.DataFrame({'map_value': map_data_lh, 'parcel': annot_lh[0].astype('int64')})\n",
    "    df_rh = pd.DataFrame({'map_value': map_data_rh, 'parcel': annot_rh[0].astype('int64')})\n",
    "\n",
    "    if annot_parcel_names_dict is not None:\n",
    "        df_lh['parcel_name'] = df_lh.apply(lambda x: annot_parcel_names_dict[annot_lh[2][int(x.parcel)].decode()], axis=1)\n",
    "        df_rh['parcel_name'] = df_rh.apply(lambda x: annot_parcel_names_dict[annot_rh[2][int(x.parcel)].decode()], axis=1)\n",
    "    else:\n",
    "        df_lh['parcel_name'] = df_lh.apply(lambda x: annot_lh[2][int(x.parcel)].decode(), axis=1)\n",
    "        df_rh['parcel_name'] = df_rh.apply(lambda x: annot_rh[2][int(x.parcel)].decode(), axis=1)\n",
    "\n",
    "    if not join_hemi:\n",
    "        df_lh['parcel_name'] = \"lh_\" + df_lh['parcel_name']\n",
    "        df_rh['parcel_name'] = \"rh_\" + df_rh['parcel_name']\n",
    "        \n",
    "    df_bh = pd.concat((df_lh, df_rh))\n",
    "    df_bh.drop(columns='parcel', inplace=True)\n",
    "\n",
    "    df_aux = df_bh.groupby('parcel_name').mean().reset_index()\n",
    "    df_aux['rotation'] = 'original'\n",
    "\n",
    "    df_rot_metrics = df_aux.copy()\n",
    "\n",
    "    for i, (p_lh, p_rh) in enumerate(zip(rot_indices_lh, rot_indices_rh)):\n",
    "        df_aux = pd.DataFrame({f'map_value': np.concatenate((map_data_lh[p_lh - 1], map_data_rh[p_rh - 1]))})\n",
    "        df_aux = pd.concat((df_bh.reset_index(drop=True)['parcel_name'], df_aux), axis=1).groupby('parcel_name').agg(agg_function).reset_index()\n",
    "        df_aux['rotation'] = f'rot{i}'\n",
    "        df_rot_metrics = pd.concat((df_rot_metrics, df_aux.copy()))\n",
    "    return df_rot_metrics\n",
    "\n",
    "\n",
    "def compute_rot_metrics_on_maps(map_data_lh, map_data_rh,\n",
    "                                map_target_data_lh, map_target_data_rh,\n",
    "                                rot_indices_lh, rot_indices_rh,\n",
    "                                corr_function=pearsonr):\n",
    "    \"\"\"Computes the correlation of a map with respect to a targer map for each spin permutation\"\"\"\n",
    "\n",
    "    map_data = np.concatenate((map_data_lh, map_data_rh))\n",
    "    map_target_data = np.concatenate((map_target_data_lh, map_target_data_rh))\n",
    "    \n",
    "    nas = np.logical_or(np.isnan(map_data), np.isnan(map_target_data))\n",
    "    corr, _ = corr_function(map_data[~nas], map_target_data[~nas])\n",
    "    df_aux = pd.DataFrame({'rotation': ['original'], 'corr_metric': [corr]})\n",
    "    df_rot_metrics = df_aux.copy()\n",
    "\n",
    "    for i, (p_lh, p_rh) in enumerate(zip(rot_indices_lh, rot_indices_rh)):\n",
    "        map_data_rot = np.concatenate((map_data_lh[p_lh - 1], map_data_rh[p_rh - 1]))\n",
    "        nas = np.logical_or(np.isnan(map_data_rot), np.isnan(map_target_data))\n",
    "        df_aux['rotation'] = f'rot{i}'\n",
    "        df_aux['corr_metric'], _ = corr_function(map_data_rot[~nas], map_target_data[~nas])\n",
    "        df_rot_metrics = pd.concat((df_rot_metrics, df_aux.copy()))\n",
    "    return df_rot_metrics\n",
    "\n",
    "\n",
    "def compute_spin_test_p_values(df_rot_metrics, column_name='map_value', tail='positive'):\n",
    "    \"\"\"Computes the p-values of the spin-test\"\"\"\n",
    "    cols_groupby = df_rot_metrics.columns.difference({'rotation', column_name}).to_list()\n",
    "    if tail=='positive':\n",
    "        df_spin_test_p_values = df_rot_metrics.groupby(cols_groupby).apply(lambda x: np.mean(x.query('rotation==\"original\"')[column_name].values <= x[column_name].values))\n",
    "    elif tail=='negative':\n",
    "        df_spin_test_p_values = df_rot_metrics.groupby(cols_groupby).apply(lambda x: np.mean(x.query('rotation==\"original\"')[column_name].values >= x[column_name].values))   \n",
    "    df_spin_test_p_values = df_spin_test_p_values.reset_index(name='p_value')\n",
    "    df_spin_test_p_values['tail'] = tail\n",
    "    return df_spin_test_p_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spin-tests for significance maps and effect size maps using the seven resting-state networks described in Yeo et al. 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getcwd()\n",
    "annot_name = 'Yeo2011_7Networks_N1000'\n",
    "annot_lh = nib.freesurfer.read_annot(f\"{data_dir}/fsaverage/label/lh.{annot_name}.annot\")\n",
    "annot_rh = nib.freesurfer.read_annot(f\"{data_dir}/fsaverage/label/rh.{annot_name}.annot\")\n",
    "\n",
    "# Spin permutations of fsaverage index computed with https://github.com/spin-test/spin-test\n",
    "# This large file (~1Gb) is not included in the repository, it can be found in:\n",
    "# https://www.dropbox.com/scl/fi/fzqz430auo3535p6mn35m/fsaverage_indices_1000_spin_permutations.mat?rlkey=y6o28kd8ojkj4a42ntva3o3ma&dl=0\n",
    "rot_indices_file = f\"{data_dir}/spin-test/fsaverage_indices_1000_spin_permutations.mat\"\n",
    "mat = scipy.io.loadmat(rot_indices_file)\n",
    "rot_indices_lh = mat['indexrotl']\n",
    "rot_indices_rh = mat['indexrotr']\n",
    "del mat\n",
    "\n",
    "# These are name replacements for the Yeo 7 Networks\n",
    "net_replacements = {'FreeSurfer_Defined_Medial_Wall': 'medial_wall',\n",
    "                    '7Networks_1': 'visual', \n",
    "                    '7Networks_2': 'somatomotor',\n",
    "                    '7Networks_3': 'dorsal_attention',\n",
    "                    '7Networks_4': 'ventral_attention',\n",
    "                    '7Networks_5': 'limbic',\n",
    "                    '7Networks_6': 'fronto_parietal',\n",
    "                    '7Networks_7': 'default_mode'}\n",
    "\n",
    "data_sets = ['main_data', 'replication_data']\n",
    "models = {'main_data': ['without_covariates', 'covariates_euler_age_etiv', 'covariates_euler_age_etiv_psqi_pss'],\n",
    "          'replication_data': ['without_covariates', 'covariates_euler_age_etiv']}\n",
    "contrasts = ['sesPrg', 'sesPost', 'groupxses']\n",
    "metrics = ['volume', 'thickness', 'area']\n",
    "map_metrics = ['partialETA2', 'signed_partialETA2', 'thr_FDRcorrP_across_hemi']\n",
    "agg_metric = 'mean'\n",
    "map_file_pattern = \"{}/{}/{}/{}.{}_sm10_{}_contrast_{}.mgh\"\n",
    "mask_file_pattern = \"{}/{}/{}.mask.mgh\"\n",
    "\n",
    "\n",
    "dfs = []\n",
    "dfs_pvalues = []\n",
    "for ds in data_sets:\n",
    "    for mod in models[ds]:\n",
    "        for c in contrasts:\n",
    "            for m in metrics:\n",
    "                for mm in map_metrics:\n",
    "                    mm_aux = mm.replace(\"thr_\", \"\").replace(\"signed_\", \"\")\n",
    "                    print(ds ,mod, c, m, mm)\n",
    "                    map_data_lh = nib.load(map_file_pattern.format(data_dir, ds, mod, \"lh\", m, mm_aux, c)).get_fdata().ravel()\n",
    "                    map_data_rh = nib.load(map_file_pattern.format(data_dir, ds, mod, \"rh\", m, mm_aux, c)).get_fdata().ravel()\n",
    "                    mask_lh = nib.load(mask_file_pattern.format(data_dir, ds, 'lh')).get_fdata().astype('bool').ravel()\n",
    "                    mask_rh = nib.load(mask_file_pattern.format(data_dir, ds, 'rh')).get_fdata().astype('bool').ravel()      \n",
    "                    map_data_lh[np.logical_not(mask_lh)]=np.nan  # Masking vertices outside the mask\n",
    "                    map_data_rh[np.logical_not(mask_rh)]=np.nan  # Masking vertices outside the mask\n",
    "                    if \"signed_\" in mm:\n",
    "                        sgn_data_lh = nib.load(map_file_pattern.format(data_dir, ds, mod, \"lh\", m, 'sgn', c)).get_fdata().ravel()\n",
    "                        sgn_data_rh = nib.load(map_file_pattern.format(data_dir, ds, mod, \"rh\", m, 'sgn', c)).get_fdata().ravel()\n",
    "                        map_data_lh = sgn_data_lh * map_data_lh\n",
    "                        map_data_rh = sgn_data_rh * map_data_rh\n",
    "                    if \"thr_\" in mm:\n",
    "                        map_data_lh = (map_data_lh > 0.95)*100  # Thresholding the significance map at alpha = 0.05 and scaling to obtain percentage\n",
    "                        map_data_rh = (map_data_rh > 0.95)*100  # Thresholding the significance map at alpha = 0.05 and scaling to obtain percentage\n",
    "                    df_rot_metrics = compute_rot_metrics_on_annot(map_data_lh, map_data_rh,\n",
    "                                                                  annot_lh, annot_rh,\n",
    "                                                                  rot_indices_lh, rot_indices_rh,\n",
    "                                                                  agg_metric, net_replacements, join_hemi=True)\n",
    "                    df_rot_metrics['data_set'] = ds\n",
    "                    df_rot_metrics['model'] = mod\n",
    "                    df_rot_metrics['contrast'] = c\n",
    "                    df_rot_metrics['metric'] = m\n",
    "                    df_rot_metrics['map_metric'] = mm\n",
    "                    df_rot_metrics['agg_metric'] = agg_metric\n",
    "                    df_rot_metrics['num_rots'] = rot_indices_lh.shape[0]\n",
    "                    dfs.append(df_rot_metrics)\n",
    "                    dfs_pvalues.append(compute_spin_test_p_values(df_rot_metrics, tail='positive'))\n",
    "                    dfs_pvalues.append(compute_spin_test_p_values(df_rot_metrics, tail='negative'))\n",
    "df_rot_metrics = pd.concat(dfs)\n",
    "df_pvalues = pd.concat(dfs_pvalues)\n",
    "del dfs, dfs_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order_rot_metrics = ['data_set', 'model', 'metric', 'contrast', 'map_metric', 'agg_metric', 'num_rots', 'rotation', 'parcel_name', 'map_value']\n",
    "column_order_pvalues = ['data_set', 'model', 'metric', 'contrast', 'map_metric', 'agg_metric', 'num_rots', 'parcel_name', 'tail', 'p_value']\n",
    "df_rot_metrics.reset_index(drop=True).loc[:,column_order_rot_metrics].to_feather(f\"{data_dir}/spin-test/yeo_spin_test_data.feather\")\n",
    "df_pvalues.reset_index(drop=True).loc[:,column_order_pvalues].to_feather(f\"{data_dir}/spin-test/yeo_spin_test_pvalues.feather\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spin-tests for dataset results comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getcwd()\n",
    "main_data_dir = f\"{data_dir}/main_data\"\n",
    "replication_data_dir = f\"{data_dir}/replication_data\"\n",
    "models = ['without_covariates', 'covariates_euler_age_etiv']\n",
    "contrasts = ['sesPrg', 'sesPost', 'groupxses']\n",
    "metrics = ['volume', 'thickness', 'area']\n",
    "map_metrics = [ 'partialETA2', 'signed_partialETA2']\n",
    "corr_functions = [pearsonr, spearmanr]\n",
    "mask_main_lh = nib.load(\"{}/lh.mask.mgh\".format(main_data_dir)).get_fdata().astype('bool').ravel()\n",
    "mask_main_rh = nib.load(\"{}/rh.mask.mgh\".format(main_data_dir)).get_fdata().astype('bool').ravel()\n",
    "mask_replication_lh = nib.load(\"{}/lh.mask.mgh\".format(replication_data_dir)).get_fdata().astype('bool').ravel()\n",
    "mask_replication_rh = nib.load(\"{}/rh.mask.mgh\".format(replication_data_dir)).get_fdata().astype('bool').ravel()\n",
    "\n",
    "\n",
    "# Spin permutations of fsaverage index computed with https://github.com/spin-test/spin-test\n",
    "# This large file (~1Gb) is the same as for the above spin-tests and it is not included in the repository, it can be found in:\n",
    "# https://www.dropbox.com/scl/fi/fzqz430auo3535p6mn35m/fsaverage_indices_1000_spin_permutations.mat?rlkey=y6o28kd8ojkj4a42ntva3o3ma&dl=0\n",
    "rot_indices_file = \"./spin-test/fsaverage_indices_1000_spin_permutations.mat\"\n",
    "mat = scipy.io.loadmat(rot_indices_file)\n",
    "rot_indices_lh = mat['indexrotl']\n",
    "rot_indices_rh = mat['indexrotr']\n",
    "del mat\n",
    "\n",
    "str_image_format = \"{}/{}/{}.{}_sm10_{}_contrast_{}.mgh\"\n",
    "             \n",
    "dfs = []\n",
    "dfs_corr_pvalue = []\n",
    "for mod in models:\n",
    "    for c in contrasts:\n",
    "        for m in metrics:\n",
    "            for mm in map_metrics:\n",
    "                mm_aux = mm.replace('signed_', '')\n",
    "                for cf in corr_functions:\n",
    "                    print(mod, c, m, mm, cf.__name__)\n",
    "                    main_map_lh = nib.load(str_image_format.format(main_data_dir, mod, \"lh\", m, mm_aux, c)).get_fdata().ravel()\n",
    "                    main_map_rh = nib.load(str_image_format.format(main_data_dir, mod, \"rh\", m, mm_aux, c)).get_fdata().ravel()\n",
    "                    replication_map_lh = nib.load(str_image_format.format(replication_data_dir, mod, \"lh\", m, mm_aux, c)).get_fdata().ravel()\n",
    "                    replication_map_rh = nib.load(str_image_format.format(replication_data_dir, mod, \"rh\", m, mm_aux, c)).get_fdata().ravel()\n",
    "                    if 'signed_' in mm:\n",
    "                        main_map_sgn_lh = nib.load(str_image_format.format(main_data_dir, mod, \"lh\", m, 'sgn', c)).get_fdata().ravel()\n",
    "                        main_map_sgn_rh = nib.load(str_image_format.format(main_data_dir, mod, \"rh\", m, 'sgn', c)).get_fdata().ravel()\n",
    "                        main_map_lh = main_map_lh*main_map_sgn_lh\n",
    "                        main_map_rh = main_map_rh*main_map_sgn_rh\n",
    "                        replication_map_sgn_lh = nib.load(str_image_format.format(replication_data_dir, mod, \"lh\", m, 'sgn', c)).get_fdata().ravel()\n",
    "                        replication_map_sgn_rh = nib.load(str_image_format.format(replication_data_dir, mod, \"rh\", m, 'sgn', c)).get_fdata().ravel()\n",
    "                        replication_map_lh = replication_map_lh*replication_map_sgn_lh\n",
    "                        replication_map_rh = replication_map_rh*replication_map_sgn_rh\n",
    "                    main_map_lh[np.logical_not(mask_main_lh)] = np.nan  # Masking vertices outside the mask\n",
    "                    main_map_rh[np.logical_not(mask_main_rh)] = np.nan  # Masking vertices outside the mask\n",
    "                    replication_map_lh[np.logical_not(mask_replication_lh)] = np.nan  # Masking vertices outside the mask\n",
    "                    replication_map_rh[np.logical_not(mask_replication_rh)] = np.nan  # Masking vertices outside the mask\n",
    "                    df_corr = compute_rot_metrics_on_maps(main_map_lh, main_map_rh, \n",
    "                                                          replication_map_lh, replication_map_rh,\n",
    "                                                          rot_indices_lh, rot_indices_rh, cf)\n",
    "                    df_corr['model'] = mod\n",
    "                    df_corr['contrast'] = c\n",
    "                    df_corr['metric'] = m\n",
    "                    df_corr['map_metric'] = mm\n",
    "                    df_corr['num_rots'] = rot_indices_lh.shape[0]\n",
    "                    df_corr['corr_function'] = cf.__name__\n",
    "                    dfs.append(df_corr)\n",
    "                    dfs_corr_pvalue.append(compute_spin_test_p_values(df_corr, 'corr_metric', tail='positive'))\n",
    "    df_corr = pd.concat(dfs)\n",
    "    df_corr_pvalues = pd.concat(dfs_corr_pvalue)\n",
    "del dfs, dfs_corr_pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order_corr = ['model', 'metric', 'contrast', 'map_metric', 'corr_function', 'num_rots', 'rotation', 'corr_metric']\n",
    "column_order_corr_pvalues = ['model', 'metric', 'contrast', 'map_metric', 'corr_function', 'num_rots', 'tail', 'p_value']\n",
    "df_corr.reset_index(drop=True).loc[:,column_order_corr].to_feather(f\"{data_dir}/spin-test/replication_spin_test_data.feather\")\n",
    "df_corr_pvalues.reset_index(drop=True).loc[:,column_order_corr_pvalues].to_feather(f\"{data_dir}/spin-test/replication_spin_test_pvalues.feather\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
